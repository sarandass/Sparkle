{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Run the below cmd in cmd prompt\n",
    "conda install -c conda-forge findspark\n",
    "'''\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark StructType & StructField"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "StructType –-> StructType is a collection or list of StructField objects. Also defines the structure of the Dataframe.\n",
    "\n",
    "StructType is a collection of StructField’s which is used to define the column name, data type and a flag for nullable or not. \n",
    "\n",
    "Using StructField we can also add nested struct schema, ArrayType for arrays and MapType for key-value pairs\n",
    "\n",
    "link: https://sparkbyexamples.com/pyspark/pyspark-structtype-and-structfield/#sql-structtype-example\n",
    "\n",
    "Sparksession link: https://sparkbyexamples.com/pyspark/pyspark-what-is-sparksession/#:~:text=getOrCreate()%20%E2%80%93%20This%20returns%20a,SparkSession%20using%20newSession()%20method.&text=This%20always%20creates%20new%20SparkSession%20object.\n",
    "\n",
    "spark-sql-functions link : https://sparkbyexamples.com/spark/spark-sql-functions/\n",
    "\n",
    "withcolumn() link: https://sparkbyexamples.com/pyspark/pyspark-withcolumn/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+----------------------+----------+--------+-----+------+------+\n",
      "|firstname             |middlename|lastname|id   |gender|salary|\n",
      "+----------------------+----------+--------+-----+------+------+\n",
      "|James                 |          |Smith   |36636|M     |3000  |\n",
      "|Michael               |Rose      |        |40288|M     |4000  |\n",
      "|Robert                |          |Williams|42114|M     |4000  |\n",
      "|Maria                 |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen1234567890987654321|Mary      |Brown   |     |F     |-1    |\n",
      "+----------------------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To create a StructType & StructField on DataFrame \n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType #--> To define the struct of DF\n",
    "\n",
    "#Sparksession link:https://sparkbyexamples.com/pyspark/pyspark-what-is-sparksession/#:~:text=getOrCreate()%20%E2%80%93%20This%20returns%20a,SparkSession%20using%20newSession()%20method.&text=This%20always%20creates%20new%20SparkSession%20object.\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\\\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\\\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\\\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\\\n",
    "    (\"Jen1234567890987654321\",\"Mary\",\"Brown\",\"\",\"F\",-1)\\\n",
    "     ]\n",
    "\n",
    "#Create StructType\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=schema,)\n",
    "\n",
    "#printSchema() method on the DataFrame shows StructType columns as “struct”.\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df.show(truncate=False) \n",
    "# if truncate=True --> will not show the whole value of a column\n",
    "# if truncate=False --> will show the whole value of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+--------------------+-----+------+------+\n",
      "|name                |id   |gender|salary|\n",
      "+--------------------+-----+------+------+\n",
      "|[James, , Smith]    |36636|M     |3100  |\n",
      "|[Michael, Rose, ]   |40288|M     |4300  |\n",
      "|[Robert, , Williams]|42114|M     |1400  |\n",
      "|[Maria, Anne, Jones]|39192|F     |5500  |\n",
      "|[Jen, Mary, Brown]  |     |F     |-1    |\n",
      "+--------------------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining nested StructType object struct\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "\n",
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating StructType object struct from JSON file\n",
    "prit(df2.schema.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'struct<firstname:string,middlename:string,lastname:string,id:string,gender:string,salary:int>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema.simpleString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------+------+\n",
      "|name                |id   |gender|salary|\n",
      "+--------------------+-----+------+------+\n",
      "|[James, , Smith]    |36636|M     |3100  |\n",
      "|[Michael, Rose, ]   |40288|M     |4300  |\n",
      "|[Robert, , Williams]|42114|M     |1400  |\n",
      "|[Maria, Anne, Jones]|39192|F     |5500  |\n",
      "|[Jen, Mary, Brown]  |     |F     |-1    |\n",
      "+--------------------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the json file and use it to create a DataFrame.\n",
    "import pyspark  \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "import json\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "\n",
    "#Load the json file and use it to create a DataFrame.\n",
    "df2_schem_json = df2.schema.json()\n",
    "schemaFromJson = StructType.fromJson(json.loads(df2_schem_json))\n",
    "\n",
    "#here we converted RDD to DF(check 'data' args). Note:parallelize() to create RDD\n",
    "df3 = spark.createDataFrame(data=spark.sparkContext.parallelize(structureData),schema=schemaFromJson)\n",
    "df3.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- OtherInfo: struct (nullable = false)\n",
      " |    |-- identifier: string (nullable = true)\n",
      " |    |-- gender: string (nullable = true)\n",
      " |    |-- salary: integer (nullable = true)\n",
      " |    |-- Salary_Grade: string (nullable = false)\n",
      "\n",
      "+--------------------+------------------------+\n",
      "|name                |OtherInfo               |\n",
      "+--------------------+------------------------+\n",
      "|[James, , Smith]    |[36636, M, 3100, Medium]|\n",
      "|[Michael, Rose, ]   |[40288, M, 4300, High]  |\n",
      "|[Robert, , Williams]|[42114, M, 1400, Low]   |\n",
      "|[Maria, Anne, Jones]|[39192, F, 5500, High]  |\n",
      "|[Jen, Mary, Brown]  |[, F, -1, Low]          |\n",
      "+--------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adding & Changing struct of the DataFrame\n",
    "\n",
    "import pyspark  \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import col,struct,when\n",
    "import json\n",
    "\n",
    "#spark-sql-functions link : https://sparkbyexamples.com/spark/spark-sql-functions/\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "\n",
    "#withcolumn() link: https://sparkbyexamples.com/pyspark/pyspark-withcolumn/\n",
    "        \n",
    "updatedDF = df2.withColumn(\"OtherInfo\", \\\n",
    "    struct(col(\"id\").alias(\"identifier\"),\\\n",
    "    col(\"gender\").alias(\"gender\"),\\\n",
    "    col(\"salary\").alias(\"salary\"),\\\n",
    "    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\\\n",
    "      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\\\n",
    "      .otherwise(\"High\").alias(\"Salary_Grade\")\\\n",
    "  )).drop(\"id\",\"gender\",\"salary\")\n",
    "\n",
    "updatedDF.printSchema()\n",
    "updatedDF.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- hobbies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+----------------+----------------+----------------+\n",
      "|            name|         hobbies|      properties|\n",
      "+----------------+----------------+----------------+\n",
      "|[James, , Smith]|[cricket, chess]|[batsman -> bat]|\n",
      "+----------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using SQL ArrayType and MapType\n",
    "\n",
    "\n",
    "'''\n",
    "Getting error need to check \"arr_map_structureData\"\n",
    "\n",
    "ArrayType link : http://nadbordrozd.github.io/blog/2016/05/22/one-weird-trick-that-will-fix-your-pyspark-schemas/\n",
    "\n",
    "'''\n",
    "import pyspark  \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, ArrayType, MapType\n",
    "from pyspark.sql.functions import col,struct,when\n",
    "import json\n",
    "\n",
    "#spark-sql-functions link : https://sparkbyexamples.com/spark/spark-sql-functions/\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "arr_map_structureData = [\\\n",
    "    ((\"James\",\"\",\"Smith\"),[\"cricket\",\"chess\"],{'batsman':'bat'})\\\n",
    "  ]\n",
    "\n",
    "\n",
    "arrayStructureSchema = StructType([\n",
    "    StructField('name', StructType([\n",
    "       StructField('firstname', StringType(), True),\n",
    "       StructField('middlename', StringType(), True),\n",
    "       StructField('lastname', StringType(), True)\n",
    "       ])),\n",
    "       StructField('hobbies', ArrayType(StringType()), True),\n",
    "       StructField('properties', MapType(StringType(),StringType()), True)\n",
    "    ])\n",
    "\n",
    "arr_map_df = spark.createDataFrame(data=arr_map_structureData,schema=arrayStructureSchema)\n",
    "arr_map_df.printSchema()\n",
    "arr_map_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('firstname', 'string'), ('middlename', 'string'), ('lastname', 'string'), ('id', 'string'), ('gender', 'string'), ('salary', 'int')]\n",
      "both column and dtype present in [('firstname', 'string'), ('middlename', 'string'), ('lastname', 'string'), ('id', 'string'), ('gender', 'string'), ('salary', 'int')]\n",
      "column present in ['firstname', 'middlename', 'lastname', 'id', 'gender', 'salary']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nBelow is for scala\\nprint(df.schema.fieldNames.contains(\"firstname\"))\\nprint(df.schema.contains(StructField(\"firstname\",StringType,true)))\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if a field exists in a DataFrame\n",
    "from pyspark.sql.functions import col,struct,when\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "\n",
    "if ('firstname','string') in df.dtypes:\n",
    "    print(f\"both column and dtype present in {df.dtypes}\")\n",
    "\n",
    "    \n",
    "if 'firstname' in df.columns:\n",
    "    print(f\"column present in {df.columns}\")\n",
    "    \n",
    "'''\n",
    "Below is for scala\n",
    "print(df.schema.fieldNames.contains(\"firstname\"))\n",
    "print(df.schema.contains(StructField(\"firstname\",StringType,true)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "#To compare two schema of df \n",
    "if df.printSchema() == df.printSchema():\n",
    "    print(\"yes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
